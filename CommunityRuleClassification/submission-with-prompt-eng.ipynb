{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":94635,"databundleVersionId":13121456,"sourceType":"competition"},{"sourceId":282742,"sourceType":"modelInstanceVersion","modelInstanceId":239467,"modelId":222398}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !uv pip install kagglehub more_itertools torch transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T11:37:53.905641Z","iopub.execute_input":"2025-10-04T11:37:53.905813Z","iopub.status.idle":"2025-10-04T11:37:53.910351Z","shell.execute_reply.started":"2025-10-04T11:37:53.905788Z","shell.execute_reply":"2025-10-04T11:37:53.909392Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport os\n\ndef is_submission():\n    return os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\")\n\npath = f\"/kaggle/input/jigsaw-agile-community-rules/{'test.csv' if is_submission() else 'test.csv'}\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-04T11:37:53.912284Z","iopub.execute_input":"2025-10-04T11:37:53.912732Z","iopub.status.idle":"2025-10-04T11:37:56.193694Z","shell.execute_reply.started":"2025-10-04T11:37:53.912713Z","shell.execute_reply":"2025-10-04T11:37:56.193092Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"data = pd.read_csv(path)\ndata.head(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T12:10:39.488693Z","iopub.execute_input":"2025-10-04T12:10:39.488979Z","iopub.status.idle":"2025-10-04T12:10:39.524224Z","shell.execute_reply.started":"2025-10-04T12:10:39.488958Z","shell.execute_reply":"2025-10-04T12:10:39.523574Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"   row_id                                               body  \\\n0       0  Banks don't want you to know this! Click here ...   \n\n                                                rule   subreddit  \\\n0  No Advertising: Spam, referral links, unsolici...  Futurology   \n\n                                  positive_example_1  \\\n0  If you could tell your younger self something ...   \n\n                                  positive_example_2  \\\n0  hunt for lady for jack off in neighbourhood ht...   \n\n                                  negative_example_1  \\\n0  Watch Golden Globe Awards 2017 Live Online in ...   \n\n                                  negative_example_2  rule_violation  \n0  DOUBLE CEE x BANDS EPPS - \"BIRDS\"\\n\\nDOWNLOAD/...               0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>body</th>\n      <th>rule</th>\n      <th>subreddit</th>\n      <th>positive_example_1</th>\n      <th>positive_example_2</th>\n      <th>negative_example_1</th>\n      <th>negative_example_2</th>\n      <th>rule_violation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Banks don't want you to know this! Click here ...</td>\n      <td>No Advertising: Spam, referral links, unsolici...</td>\n      <td>Futurology</td>\n      <td>If you could tell your younger self something ...</td>\n      <td>hunt for lady for jack off in neighbourhood ht...</td>\n      <td>Watch Golden Globe Awards 2017 Live Online in ...</td>\n      <td>DOUBLE CEE x BANDS EPPS - \"BIRDS\"\\n\\nDOWNLOAD/...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"### Steps for initial solution\n\n- Step - 1 Add a column for expanding the rule by describing the given rule and make it understandable along with the prompt.\n- Step - 2 Each row updated with prompt with positive and negative examples. \n- Step - 3 Then finally setup system prompt by describing the nature of the tool and get the otuput as voilation or nonvoilation along with other information.\n            ","metadata":{}},{"cell_type":"code","source":"import kagglehub\nimport more_itertools\nimport pandas as pd\nimport torch\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForCausalLM","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T11:37:56.299183Z","iopub.execute_input":"2025-10-04T11:37:56.300034Z","iopub.status.idle":"2025-10-04T11:38:08.341688Z","shell.execute_reply.started":"2025-10-04T11:37:56.300007Z","shell.execute_reply":"2025-10-04T11:38:08.340810Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"hugging_face_model_name=\"google/gemma-3/transformers/gemma-3-1b-it\"\nGEMMA_PATH = kagglehub.model_download(hugging_face_model_name)\nprocessor = AutoTokenizer.from_pretrained(GEMMA_PATH)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = AutoModelForCausalLM.from_pretrained(GEMMA_PATH).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T11:38:08.342522Z","iopub.execute_input":"2025-10-04T11:38:08.342866Z","iopub.status.idle":"2025-10-04T11:38:44.982958Z","shell.execute_reply.started":"2025-10-04T11:38:08.342849Z","shell.execute_reply":"2025-10-04T11:38:44.982137Z"}},"outputs":[{"name":"stderr","text":"2025-10-04 11:38:19.145736: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759577899.468952      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759577899.558566      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def expand_rules(rule, model, processor, device):\n\n    SYS_PROMPT_RULE = \"\"\"\n    You are an expert with understanding of community guidlines and related keywords.\n    For a given community rule provided, you go through its keywords and exapand each keyword in details. \n    \n    Output should only contain the expanded rules no explanatory text.\n    \"\"\"\n    \n    USER_PROMPT_RULE = f\"\"\"\n    Expand below rule\n    \n    {rule}\n    \n    \"\"\"\n    \n    prompt_rule_text = (\n        f\"<start_of_turn>system\\n{SYS_PROMPT_RULE}<end_of_turn>\\n\"\n        f\"<start_of_turn>user\\n{USER_PROMPT_RULE}<end_of_turn>\\n\"\n        f\"<start_of_turn>model\\n\"\n    )\n\n    rule_inputs = processor(prompt_rule_text, return_tensors=\"pt\").to(device)\n    \n    output_rules = model.generate(\n        **rule_inputs,\n        max_new_tokens=300,\n        repetition_penalty=1,\n        eos_token_id=processor.eos_token_id,\n        pad_token_id=processor.eos_token_id,\n        return_dict_in_generate=True\n    )\n    \n    generated_tokens = output_rules.sequences[:, rule_inputs[\"input_ids\"].shape[-1]:]\n    decoded_text = processor.batch_decode(generated_tokens, skip_special_tokens=True)\n\n    return decoded_text[0].split(\"--\")[0]\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T12:07:20.702709Z","iopub.execute_input":"2025-10-04T12:07:20.703493Z","iopub.status.idle":"2025-10-04T12:07:20.710260Z","shell.execute_reply.started":"2025-10-04T12:07:20.703459Z","shell.execute_reply":"2025-10-04T12:07:20.709470Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import re\nrule_df = data[['rule']].drop_duplicates().reset_index(drop=True)\nrule_df['expanded_rule'] = [re.sub(r'\\n{3,}', \"\", expand_rules(rule, model, processor, device)) for rule in rule_df.rule]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T12:10:44.333709Z","iopub.execute_input":"2025-10-04T12:10:44.333998Z","iopub.status.idle":"2025-10-04T12:10:58.866817Z","shell.execute_reply.started":"2025-10-04T12:10:44.333975Z","shell.execute_reply":"2025-10-04T12:10:58.866215Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"data = data.merge(rule_df, on=\"rule\", how=\"left\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T12:24:03.952400Z","iopub.execute_input":"2025-10-04T12:24:03.952666Z","iopub.status.idle":"2025-10-04T12:24:03.959349Z","shell.execute_reply.started":"2025-10-04T12:24:03.952645Z","shell.execute_reply":"2025-10-04T12:24:03.958622Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"import torch\nimport math\n\ndef classify_comment_in_batch(data, model, processor, device, batch_size=16):\n\n    results = []\n    num_batches = math.ceil(len(data) / batch_size)\n\n    for i in range(num_batch):\n        \n        batch = df.iloc[i*batch_size:(i+1)*batch_size]\n        prompts = []\n\n        for _, data_row in batch.iterrows():\n    \n            SYSTEM_PROMPT_CLASSIFICATION = \"\"\"\n            \n            you are a community rule voilation inspector. \n            if you are give the rule with context and target comment along with negative and positive comments you can decide if the target comment is in voilation of the specific rule.\n            you will use positive comment to understand how those comments voilates the rule and negative comments to understand why negative comments are not breaking the rules,\n            you are required to answer only one of the 2 values, 0 or 1. 0 denotes \"not voilation\" and 1 denotes \"voilation\".\n            \n            output should be given between 0 or 1. and strictly float.\n            \n            \"\"\"\n            \n            USER_PROMPT_CLASSIFICATION = f\"\"\"\n            Classify the below comment based on the rule given, \n            Rule : {data_row.expanded_rule}\n            comment = {data_row.body}\n            \n            below are the positive comment (voilation) and negative comment (non voilation) related to the comment, \n            use these commnet to better understand the above comment: \n            \n            positive comment : {data_row.positive_example_1, data_row.positive_example_2}\n            negative comment : {data_row.negative_example_1, data_row.negative_example_2}\n            \n            \"\"\"\n        \n            prompt_classify_text = (\n                f\"<start_of_turn>system\\n{SYSTEM_PROMPT_CLASSIFICATION}<end_of_turn>\\n\"\n                f\"<start_of_turn>user\\n{USER_PROMPT_CLASSIFICATION}<end_of_turn>\\n\"\n                f\"<start_of_turn>model\\n\"\n            )\n            \n            prompts.append(prompt_classify_text)\n\n        inputs = processor(prompts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n\n        with torch.no_grad():\n            outputs = model.generate(\n                **inputs,\n                max_new_tokens=100,\n                repetition_penalty=1.3,\n                eos_token_id=processor.eos_token_id,\n                pad_token_id=processor.eos_token_id,\n                return_dict_in_generate=True\n            )\n    \n    output_classify = model.generate(\n        **classifier_inputs,\n        max_new_tokens=1,\n        repetition_penalty=1.3,\n        eos_token_id=processor.eos_token_id,\n        pad_token_id=processor.eos_token_id,\n        return_dict_in_generate=True\n    )\n    \n    generated_tokens = output_classify.sequences[:, classifier_inputs[\"input_ids\"].shape[-1]:]\n    decoded_text = processor.batch_decode(generated_tokens, skip_special_tokens=True)\n    return decoded_text[0].split(\"--\")[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T10:50:02.651836Z","iopub.execute_input":"2025-10-04T10:50:02.652571Z","iopub.status.idle":"2025-10-04T10:50:02.658232Z","shell.execute_reply.started":"2025-10-04T10:50:02.652543Z","shell.execute_reply":"2025-10-04T10:50:02.657567Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"columns = [classify_comment_with_rule(row, model, processor, device) for _, row in data.iterrows()]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T10:50:05.886240Z","iopub.execute_input":"2025-10-04T10:50:05.886966Z","iopub.status.idle":"2025-10-04T10:50:08.963593Z","shell.execute_reply.started":"2025-10-04T10:50:05.886940Z","shell.execute_reply":"2025-10-04T10:50:08.962791Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"df =  data[['row_id']].copy()\ndf['rule_violation'] = columns\ndf.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T10:51:02.245358Z","iopub.execute_input":"2025-10-04T10:51:02.246082Z","iopub.status.idle":"2025-10-04T10:51:02.251068Z","shell.execute_reply.started":"2025-10-04T10:51:02.246055Z","shell.execute_reply":"2025-10-04T10:51:02.250187Z"}},"outputs":[],"execution_count":42}]}